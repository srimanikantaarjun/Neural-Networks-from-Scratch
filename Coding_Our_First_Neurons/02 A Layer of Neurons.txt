Inputs : [1, 2, 3, 2.5] 

We have 3 neurons so we have 3 sets/lists of weights and for 4 inputs : 

Weights for 1st neuron : [0.2, 0.8, -0.5, 10] 

Weights for 2nd neuron : [0.5, -0.91, 0.26, -0.5] 

Weights for 3rd neuron : [-0.26, -0.27, 0.17, 0.87] 

Similarly, 3 bias, 1 for each neuron : 

Bias for 1st neuron : 2 

Bias for 2nd neuron : 3 

Bias for 3rd neuron : 0.5 

Layer output : (27.3, 1.21, 2.385) 

In the above code, we have three sets of weights and three biases, which define three neurons. Each neuron is “connected” to the same inputs. 
The difference is in the separate weights and bias that each neuron applies to the input. This is called a fully connected neural 
network — every neuron in the current layer has connections to every neuron from the previous layer. This is a very common type of neural network, 
but it should be noted that there is no requirement to fully connect everything like this.

Layer Output using a function: [27.3, 1.21, 2.385] 

